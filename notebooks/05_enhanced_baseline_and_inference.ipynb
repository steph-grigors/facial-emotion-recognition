{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Enhanced Baseline CNN & Inference\n",
    "\n",
    "**Goals**:\n",
    "1. Enhance the baseline CNN with better techniques\n",
    "2. Train the improved model\n",
    "3. Create inference pipeline for live predictions\n",
    "\n",
    "**Enhancements we'll implement**:\n",
    "- Stronger data augmentation\n",
    "- Deeper architecture\n",
    "- Better regularization\n",
    "- Learning rate scheduling\n",
    "- Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T16:59:11.518001Z",
     "iopub.status.busy": "2025-11-22T16:59:11.516774Z",
     "iopub.status.idle": "2025-11-22T16:59:18.785531Z",
     "shell.execute_reply": "2025-11-22T16:59:18.784707Z",
     "shell.execute_reply.started": "2025-11-22T16:59:11.517960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T17:18:35.143673Z",
     "iopub.status.busy": "2025-11-22T17:18:35.141632Z",
     "iopub.status.idle": "2025-11-22T17:18:35.179832Z",
     "shell.execute_reply": "2025-11-22T17:18:35.179023Z",
     "shell.execute_reply.started": "2025-11-22T17:18:35.143630Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../configs/config.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4198254473.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../configs/config.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../configs/config.yaml'"
     ]
    }
   ],
   "source": [
    "# Load config\n",
    "with open('../configs/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(os.path.dirname(Path.cwd()))\n",
    "PROCESSED_DIR = PROJECT_ROOT / config['data']['processed_dir']\n",
    "MODELS_DIR = PROJECT_ROOT / config['paths']['final_models_dir']\n",
    "MODELS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Training params\n",
    "NUM_CLASSES = config['data']['num_classes']\n",
    "CLASS_NAMES = config['data']['classes']\n",
    "BATCH_SIZE = config['training']['batch_size']\n",
    "LEARNING_RATE = config['training']['learning_rate']\n",
    "EPOCHS = 50  # More epochs for better training\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Classes: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T17:18:38.065270Z",
     "iopub.status.busy": "2025-11-22T17:18:38.064516Z",
     "iopub.status.idle": "2025-11-22T17:18:38.093394Z",
     "shell.execute_reply": "2025-11-22T17:18:38.091232Z",
     "shell.execute_reply.started": "2025-11-22T17:18:38.065237Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1543333275.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Stronger augmentation for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m train_transform = transforms.Compose([\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomHorizontalFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomRotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Increased rotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "# Stronger augmentation for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((config['data']['image_size'][0], config['data']['image_size'][0])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(20),  # Increased rotation\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),  # Stronger color jitter\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random shift\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),  # Add perspective\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=config['data']['normalize_mean'],\n",
    "        std=config['data']['normalize_std']\n",
    "    ),\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.1))  # Random erasing for robustness\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((config['data']['image_size'][0], config['data']['image_size'][0])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=config['data']['normalize_mean'],\n",
    "        std=config['data']['normalize_std']\n",
    "    )\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Enhanced data augmentation configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T17:18:38.254014Z",
     "iopub.status.busy": "2025-11-22T17:18:38.253589Z",
     "iopub.status.idle": "2025-11-22T17:18:38.479975Z",
     "shell.execute_reply": "2025-11-22T17:18:38.479420Z",
     "shell.execute_reply.started": "2025-11-22T17:18:38.253983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded\n",
      "  Training samples: 39823\n",
      "  Validation samples: 4978\n",
      "  Test samples: 4978\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(str(PROCESSED_DIR / 'train'), transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(str(PROCESSED_DIR / 'val'), transform=val_transform)\n",
    "test_dataset = datasets.ImageFolder(str(PROCESSED_DIR / 'test'), transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"‚úÖ Data loaded\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T17:18:39.496502Z",
     "iopub.status.busy": "2025-11-22T17:18:39.496095Z",
     "iopub.status.idle": "2025-11-22T17:18:40.055055Z",
     "shell.execute_reply": "2025-11-22T17:18:40.054380Z",
     "shell.execute_reply.started": "2025-11-22T17:18:39.496471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced CNN created\n",
      "  Total parameters: 13,607,239\n",
      "  Trainable parameters: 13,607,239\n"
     ]
    }
   ],
   "source": [
    "class EnhancedCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced CNN with:\n",
    "    - Deeper architecture (4 conv blocks instead of 3)\n",
    "    - Batch normalization after each conv\n",
    "    - Dropout for regularization\n",
    "    - Residual connections (skip connections)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=7, dropout=0.5):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        \n",
    "        # Conv Block 1: 3 -> 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.2)\n",
    "        )\n",
    "        \n",
    "        # Conv Block 2: 64 -> 128\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        \n",
    "        # Conv Block 3: 128 -> 256\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.4)\n",
    "        )\n",
    "        \n",
    "        # Conv Block 4: 256 -> 512\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((4, 4)),\n",
    "            nn.Dropout2d(0.5)\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "model = EnhancedCNN(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"‚úÖ Enhanced CNN created\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup with Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T17:18:41.290545Z",
     "iopub.status.busy": "2025-11-22T17:18:41.290128Z",
     "iopub.status.idle": "2025-11-22T17:18:41.306309Z",
     "shell.execute_reply": "2025-11-22T17:18:41.304236Z",
     "shell.execute_reply.started": "2025-11-22T17:18:41.290515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training setup complete\n",
      "  Optimizer: AdamW with weight decay\n",
      "  Scheduler: ReduceLROnPlateau\n",
      "  Early stopping: patience=10\n"
     ]
    }
   ],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "\n",
    "# Learning rate scheduler - reduce on plateau\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    patience=5,\n",
    "    factor=0.5,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "print(\"‚úÖ Training setup complete\")\n",
    "print(f\"  Optimizer: AdamW with weight decay\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"  Early stopping: patience=10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T17:18:42.645558Z",
     "iopub.status.busy": "2025-11-22T17:18:42.645156Z",
     "iopub.status.idle": "2025-11-22T17:18:42.658201Z",
     "shell.execute_reply": "2025-11-22T17:18:42.656777Z",
     "shell.execute_reply.started": "2025-11-22T17:18:42.645528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training functions ready\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return running_loss / len(loader), correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return running_loss / len(loader), correct / total\n",
    "\n",
    "print(\"‚úÖ Training functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Enhanced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T17:18:43.851433Z",
     "iopub.status.busy": "2025-11-22T17:18:43.851038Z",
     "iopub.status.idle": "2025-11-22T17:32:04.873243Z",
     "shell.execute_reply": "2025-11-22T17:32:04.871584Z",
     "shell.execute_reply.started": "2025-11-22T17:18:43.851403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üî• Training Enhanced CNN\n",
      "======================================================================\n",
      "\n",
      "Epoch 1/50\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m     24\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate(model, val_loader, criterion, device)\n",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 20\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üî• Training Enhanced CNN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Track history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Get current learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
    "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), MODELS_DIR / 'enhanced_cnn_best.pth')\n",
    "        print(f\"üíæ Saved new best model (Val Acc: {val_acc*100:.2f}%)\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"\\n‚ö†Ô∏è  Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete!\")\n",
    "print(f\"   Best validation accuracy: {best_val_acc*100:.2f}%\")\n",
    "print(f\"   Model saved: {MODELS_DIR / 'enhanced_cnn_best.pth'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train', marker='o', markersize=4)\n",
    "axes[0].plot(history['val_loss'], label='Validation', marker='o', markersize=4)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot([x*100 for x in history['train_acc']], label='Train', marker='o', markersize=4)\n",
    "axes[1].plot([x*100 for x in history['val_acc']], label='Validation', marker='o', markersize=4)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "axes[2].plot(history['lr'], marker='o', markersize=4, color='green')\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final metrics:\")\n",
    "print(f\"  Best validation accuracy: {max(history['val_acc'])*100:.2f}%\")\n",
    "print(f\"  Final training accuracy: {history['train_acc'][-1]*100:.2f}%\")\n",
    "print(f\"  Final validation accuracy: {history['val_acc'][-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(MODELS_DIR / 'enhanced_cnn_best.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on test set\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "print(\"\\nüß™ Evaluating on test set...\")\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = (all_preds == all_labels).sum() / len(all_labels)\n",
    "\n",
    "print(f\"\\n‚úÖ Test Set Results:\")\n",
    "print(f\"   Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"   Total samples: {len(all_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(all_labels, all_preds, target_names=CLASS_NAMES, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=CLASS_NAMES,\n",
    "    yticklabels=CLASS_NAMES,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.title(f'Confusion Matrix - Enhanced CNN\\nTest Accuracy: {test_accuracy*100:.2f}%', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(image_path, model, device, class_names, transform):\n",
    "    \"\"\"\n",
    "    Predict emotion from an image\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to image file or PIL Image\n",
    "        model: Trained model\n",
    "        device: CPU or GPU\n",
    "        class_names: List of emotion labels\n",
    "        transform: Image transforms\n",
    "    \n",
    "    Returns:\n",
    "        prediction: Predicted class name\n",
    "        confidence: Confidence score (0-100)\n",
    "        probabilities: All class probabilities\n",
    "        original_image: Original PIL image\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    if isinstance(image_path, str):\n",
    "        original_image = Image.open(image_path).convert('RGB')\n",
    "    else:\n",
    "        original_image = image_path.convert('RGB')\n",
    "    \n",
    "    # Transform and predict\n",
    "    image_tensor = transform(original_image).unsqueeze(0).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "    \n",
    "    prediction = class_names[predicted.item()]\n",
    "    confidence = confidence.item() * 100\n",
    "    probs = probabilities.cpu().numpy()[0] * 100\n",
    "    \n",
    "    return prediction, confidence, probs, original_image\n",
    "\n",
    "# Inference transform (no augmentation)\n",
    "inference_transform = transforms.Compose([\n",
    "    transforms.Resize((config['data']['image_size'][0], config['data']['image_size'][0])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=config['data']['normalize_mean'],\n",
    "        std=config['data']['normalize_std']\n",
    "    )\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Inference pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Live Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random test images for demonstration\n",
    "import random\n",
    "\n",
    "test_dir = PROCESSED_DIR / 'test'\n",
    "sample_images = []\n",
    "\n",
    "for emotion in CLASS_NAMES:\n",
    "    emotion_dir = test_dir / emotion\n",
    "    if emotion_dir.exists():\n",
    "        images = list(emotion_dir.glob(\"*.jpg\"))[:2]  # Get 2 from each class\n",
    "        sample_images.extend(images)\n",
    "\n",
    "# Randomly select samples\n",
    "sample_images = random.sample(sample_images, min(8, len(sample_images)))\n",
    "\n",
    "print(f\"Selected {len(sample_images)} sample images for prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and visualize\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_path in enumerate(sample_images):\n",
    "    if idx >= 8:\n",
    "        break\n",
    "    \n",
    "    # Predict\n",
    "    prediction, confidence, probs, original_image = predict_emotion(\n",
    "        img_path, model, device, CLASS_NAMES, inference_transform\n",
    "    )\n",
    "    \n",
    "    # True label\n",
    "    true_label = img_path.parent.name\n",
    "    \n",
    "    # Display\n",
    "    axes[idx].imshow(original_image)\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # Color based on correctness\n",
    "    color = 'green' if prediction == true_label else 'red'\n",
    "    \n",
    "    axes[idx].set_title(\n",
    "        f'True: {true_label}\\nPred: {prediction}\\n({confidence:.1f}%)',\n",
    "        fontsize=10,\n",
    "        color=color,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Enhanced CNN - Live Predictions', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Live prediction demonstration complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Single Prediction with Probability Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one image for detailed analysis\n",
    "if sample_images:\n",
    "    test_image = sample_images[0]\n",
    "    \n",
    "    prediction, confidence, probs, original_image = predict_emotion(\n",
    "        test_image, model, device, CLASS_NAMES, inference_transform\n",
    "    )\n",
    "    \n",
    "    true_label = test_image.parent.name\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Show image\n",
    "    axes[0].imshow(original_image)\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title(\n",
    "        f'True: {true_label}\\nPredicted: {prediction}\\nConfidence: {confidence:.1f}%',\n",
    "        fontsize=14,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "    \n",
    "    # Show probability distribution\n",
    "    colors = ['coral' if CLASS_NAMES[i] == prediction else 'skyblue' for i in range(len(CLASS_NAMES))]\n",
    "    axes[1].barh(CLASS_NAMES, probs, color=colors)\n",
    "    axes[1].set_xlabel('Probability (%)', fontsize=12)\n",
    "    axes[1].set_title('Emotion Probability Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlim(0, 100)\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for i, (name, prob) in enumerate(zip(CLASS_NAMES, probs)):\n",
    "        axes[1].text(prob + 1, i, f'{prob:.1f}%', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüéØ Detailed Prediction:\")\n",
    "    print(f\"   Image: {test_image.name}\")\n",
    "    print(f\"   True Label: {true_label}\")\n",
    "    print(f\"   Predicted: {prediction}\")\n",
    "    print(f\"   Confidence: {confidence:.2f}%\")\n",
    "    print(f\"\\n   All Probabilities:\")\n",
    "    for name, prob in zip(CLASS_NAMES, probs):\n",
    "        print(f\"      {name:10s}: {prob:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Your Own Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace with path to your own image!\n",
    "YOUR_IMAGE_PATH = \"path/to/your/image.jpg\"\n",
    "\n",
    "# Uncomment and run when you have your own image:\n",
    "# try:\n",
    "#     prediction, confidence, probs, original_image = predict_emotion(\n",
    "#         YOUR_IMAGE_PATH, model, device, CLASS_NAMES, inference_transform\n",
    "#     )\n",
    "#     \n",
    "#     # Visualize\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "#     \n",
    "#     axes[0].imshow(original_image)\n",
    "#     axes[0].axis('off')\n",
    "#     axes[0].set_title(f'Predicted: {prediction}\\nConfidence: {confidence:.1f}%', \n",
    "#                      fontsize=14, fontweight='bold')\n",
    "#     \n",
    "#     colors = ['coral' if CLASS_NAMES[i] == prediction else 'skyblue' for i in range(len(CLASS_NAMES))]\n",
    "#     axes[1].barh(CLASS_NAMES, probs, color=colors)\n",
    "#     axes[1].set_xlabel('Probability (%)', fontsize=12)\n",
    "#     axes[1].set_title('Emotion Probabilities', fontsize=14, fontweight='bold')\n",
    "#     axes[1].set_xlim(0, 100)\n",
    "#     \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     \n",
    "#     print(f\"üéØ Your Image Prediction: {prediction} ({confidence:.1f}%)\")\n",
    "#     \n",
    "# except FileNotFoundError:\n",
    "#     print(f\"‚ùå Image not found: {YOUR_IMAGE_PATH}\")\n",
    "#     print(\"Please update YOUR_IMAGE_PATH with a valid image file!\")\n",
    "\n",
    "print(\"üí° Update YOUR_IMAGE_PATH and uncomment the code above to predict on your own images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüèÜ Enhanced CNN Performance:\")\n",
    "print(f\"   Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"   Best Val Accuracy: {best_val_acc*100:.2f}%\")\n",
    "print(f\"   Total Parameters: {total_params:,}\")\n",
    "\n",
    "print(f\"\\nüìà Improvements over Baseline:\")\n",
    "print(f\"   Baseline CNN: 65.81%\")\n",
    "print(f\"   Enhanced CNN: {test_accuracy*100:.2f}%\")\n",
    "print(f\"   Improvement: {(test_accuracy*100 - 65.81):.2f}%\")\n",
    "\n",
    "print(f\"\\n‚ú® Key Enhancements:\")\n",
    "print(f\"   ‚Ä¢ Deeper architecture (4 conv blocks vs 3)\")\n",
    "print(f\"   ‚Ä¢ Stronger data augmentation\")\n",
    "print(f\"   ‚Ä¢ Dropout regularization\")\n",
    "print(f\"   ‚Ä¢ AdamW optimizer with weight decay\")\n",
    "print(f\"   ‚Ä¢ Learning rate scheduling\")\n",
    "print(f\"   ‚Ä¢ Early stopping\")\n",
    "print(f\"   ‚Ä¢ Gradient clipping\")\n",
    "\n",
    "print(f\"\\nüíæ Saved Models:\")\n",
    "print(f\"   {MODELS_DIR / 'enhanced_cnn_best.pth'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Project Complete! Ready for Portfolio\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "**Your project is now complete! üéâ**\n",
    "\n",
    "**What you've built:**\n",
    "1. ‚úÖ Complete data exploration and preprocessing pipeline\n",
    "2. ‚úÖ Baseline CNN with 65.81% accuracy\n",
    "3. ‚úÖ Transfer learning with ResNet50 and EfficientNet\n",
    "4. ‚úÖ Enhanced CNN with improved techniques\n",
    "5. ‚úÖ Live inference pipeline for predictions\n",
    "6. ‚úÖ Comprehensive visualizations and metrics\n",
    "\n",
    "**For your portfolio:**\n",
    "- Document the journey from baseline to enhanced model\n",
    "- Include confusion matrices and training curves\n",
    "- Explain key architectural decisions\n",
    "- Show live prediction examples\n",
    "- Discuss challenges (e.g., transfer learning underperforming)\n",
    "\n",
    "**Potential extensions:**\n",
    "- Deploy as a web app (Gradio/Streamlit)\n",
    "- Real-time webcam emotion detection\n",
    "- Ensemble methods\n",
    "- Fine-tune transfer learning models\n",
    "- Multi-face detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
