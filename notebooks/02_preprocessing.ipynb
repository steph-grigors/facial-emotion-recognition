{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÅ Data Preprocessing & Split Creation\n",
    "\n",
    "**Goal**: Create train/val/test splits and prepare data for training\n",
    "\n",
    "**What this notebook does**:\n",
    "1. Load image paths from EDA\n",
    "2. Create stratified train/val/test splits\n",
    "3. Copy/move files to split directories\n",
    "4. Verify splits\n",
    "5. Test data pipeline\n",
    "\n",
    "**Author**: Your Name  \n",
    "**Date**: YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T14:09:22.523308Z",
     "iopub.status.busy": "2025-11-18T14:09:22.522929Z",
     "iopub.status.idle": "2025-11-18T14:09:24.159369Z",
     "shell.execute_reply": "2025-11-18T14:09:24.158588Z",
     "shell.execute_reply.started": "2025-11-18T14:09:22.523279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "# Set seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"‚úÖ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T14:09:27.283470Z",
     "iopub.status.busy": "2025-11-18T14:09:27.282620Z",
     "iopub.status.idle": "2025-11-18T14:09:27.303857Z",
     "shell.execute_reply": "2025-11-18T14:09:27.303145Z",
     "shell.execute_reply.started": "2025-11-18T14:09:27.283446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split ratios: 0.8/0.1/0.1\n",
      "Emotions: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "# Load split ratios from config\n",
    "with open('../configs/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "TRAIN_RATIO = config['data']['train_split']  # 0.8\n",
    "VAL_RATIO = config['data']['val_split']      # 0.1\n",
    "TEST_RATIO = config['data']['test_split']    # 0.1\n",
    "\n",
    "print(f\"Split ratios: {TRAIN_RATIO}/{VAL_RATIO}/{TEST_RATIO}\")\n",
    "\n",
    "# Paths\n",
    "RAW_DIR = Path('../data/raw')\n",
    "PROCESSED_DIR = Path('../data/processed')\n",
    "\n",
    "# Auto-detect emotion classes\n",
    "EMOTIONS = sorted([d.name for d in RAW_DIR.iterdir() if d.is_dir()])\n",
    "print(f\"Emotions: {EMOTIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Image Paths\n",
    "\n",
    "**Hint**: Use the CSV from EDA or scan directories again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T14:09:42.105547Z",
     "iopub.status.busy": "2025-11-18T14:09:42.104762Z",
     "iopub.status.idle": "2025-11-18T14:09:42.169719Z",
     "shell.execute_reply": "2025-11-18T14:09:42.168961Z",
     "shell.execute_reply.started": "2025-11-18T14:09:42.105512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 49779 images from EDA results\n",
      "\n",
      "Class distribution:\n",
      "emotion\n",
      "happy       11398\n",
      "neutral      8166\n",
      "sad          6535\n",
      "angry        5920\n",
      "disgust      5920\n",
      "fear         5920\n",
      "surprise     5920\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Load from EDA results\n",
    "df = pd.read_csv('../results/metrics/all_images.csv')\n",
    "print(f\"Loaded {len(df)} images from EDA results\")\n",
    "\n",
    "# Option 2: Scan directories (if CSV not available)\n",
    "# TODO: Implement directory scanning if needed\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Stratified Splits\n",
    "\n",
    "**Key**: Use `stratify` parameter to maintain class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T14:12:22.475404Z",
     "iopub.status.busy": "2025-11-18T14:12:22.474993Z",
     "iopub.status.idle": "2025-11-18T14:12:22.525585Z",
     "shell.execute_reply": "2025-11-18T14:12:22.524862Z",
     "shell.execute_reply.started": "2025-11-18T14:12:22.475374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 39823 images\n",
      "Val:   4978 images\n",
      "Test:  4978 images\n",
      "Total: 49779 images\n"
     ]
    }
   ],
   "source": [
    "# Split: train + (val+test)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=(VAL_RATIO + TEST_RATIO),\n",
    "    stratify=df['emotion'],\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Split: val + test\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,  # TODO: Replace with calculated value\n",
    "    stratify=temp_df['emotion'],\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)} images\")\n",
    "print(f\"Val:   {len(val_df)} images\")\n",
    "print(f\"Test:  {len(test_df)} images\")\n",
    "print(f\"Total: {len(train_df) + len(val_df) + len(test_df)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Split Distribution\n",
    "\n",
    "**Check**: Each emotion should have same ratio in all splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T14:12:26.281067Z",
     "iopub.status.busy": "2025-11-18T14:12:26.280669Z",
     "iopub.status.idle": "2025-11-18T14:12:26.303061Z",
     "shell.execute_reply": "2025-11-18T14:12:26.302374Z",
     "shell.execute_reply.started": "2025-11-18T14:12:26.281038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          train   val  test  total  train_%  val_%  test_%\n",
      "emotion                                                   \n",
      "angry      4736   592   592   5920     80.0   10.0    10.0\n",
      "disgust    4736   592   592   5920     80.0   10.0    10.0\n",
      "fear       4736   592   592   5920     80.0   10.0    10.0\n",
      "happy      9118  1140  1140  11398     80.0   10.0    10.0\n",
      "neutral    6533   816   817   8166     80.0   10.0    10.0\n",
      "sad        5228   654   653   6535     80.0   10.0    10.0\n",
      "surprise   4736   592   592   5920     80.0   10.0    10.0\n"
     ]
    }
   ],
   "source": [
    "# Create verification DataFrame\n",
    "verification = pd.DataFrame({\n",
    "    'train': train_df['emotion'].value_counts().sort_index(),\n",
    "    'val': val_df['emotion'].value_counts().sort_index(),\n",
    "    'test': test_df['emotion'].value_counts().sort_index()\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "verification['total'] = verification.sum(axis=1)\n",
    "verification['train_%'] = (verification['train'] / verification['total'] * 100).round(1)\n",
    "verification['val_%'] = (verification['val'] / verification['total'] * 100).round(1)\n",
    "verification['test_%'] = (verification['test'] / verification['total'] * 100).round(1)\n",
    "\n",
    "print(verification)\n",
    "\n",
    "# TODO: Add assertions to verify splits are within acceptable range\n",
    "# Example: assert all train percentages are between 79% and 81%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T14:12:36.542153Z",
     "iopub.status.busy": "2025-11-18T14:12:36.541025Z",
     "iopub.status.idle": "2025-11-18T14:12:36.563959Z",
     "shell.execute_reply": "2025-11-18T14:12:36.562673Z",
     "shell.execute_reply.started": "2025-11-18T14:12:36.542118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Directory structure created\n",
      "\n",
      "Structure:\n",
      "processed/\n",
      "‚îú‚îÄ‚îÄ train/angry/\n",
      "‚îú‚îÄ‚îÄ val/angry/\n",
      "‚îî‚îÄ‚îÄ test/angry/\n"
     ]
    }
   ],
   "source": [
    "# Create processed data directories\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for emotion in EMOTIONS:\n",
    "        dir_path = PROCESSED_DIR / split / emotion\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Directory structure created\")\n",
    "print(f\"\\nStructure:\")\n",
    "print(f\"processed/\")\n",
    "print(f\"‚îú‚îÄ‚îÄ train/{EMOTIONS[0]}/\")\n",
    "print(f\"‚îú‚îÄ‚îÄ val/{EMOTIONS[0]}/\")\n",
    "print(f\"‚îî‚îÄ‚îÄ test/{EMOTIONS[0]}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Copy Files to Splits\n",
    "\n",
    "**Choice**: Copy (safe) or Move (saves space)\n",
    "\n",
    "**Warning**: Moving will delete files from raw directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T14:19:35.307641Z",
     "iopub.status.busy": "2025-11-18T14:19:35.305632Z",
     "iopub.status.idle": "2025-11-18T14:20:04.273690Z",
     "shell.execute_reply": "2025-11-18T14:20:04.272990Z",
     "shell.execute_reply.started": "2025-11-18T14:19:35.307596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39823/39823 [00:23<00:00, 1719.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing val set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4978/4978 [00:02<00:00, 1683.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4978/4978 [00:02<00:00, 1757.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ File transfer complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose operation: 'copy' or 'move'\n",
    "OPERATION = 'copy'  # TODO: Change to 'move' if you want to move files\n",
    "\n",
    "def transfer_files(df, split_name):\n",
    "    \"\"\"Copy or move files to split directory\"\"\"\n",
    "    print(f\"\\nProcessing {split_name} set...\")\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        src = Path(row['path'])\n",
    "        dst = PROCESSED_DIR / split_name / row['emotion'] / src.name\n",
    "        \n",
    "        # TODO: Implement copy or move logic\n",
    "        if OPERATION == 'copy':\n",
    "            shutil.copy2(src, dst)\n",
    "        elif OPERATION == 'move':\n",
    "            shutil.move(src, dst)\n",
    "        # TODO: Add error handling\n",
    "\n",
    "# Execute transfer\n",
    "transfer_files(train_df, 'train')\n",
    "transfer_files(val_df, 'val')\n",
    "transfer_files(test_df, 'test')\n",
    "\n",
    "print(\"\\n‚úÖ File transfer complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Verify File Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T14:20:07.043258Z",
     "iopub.status.busy": "2025-11-18T14:20:07.042870Z",
     "iopub.status.idle": "2025-11-18T14:20:07.167887Z",
     "shell.execute_reply": "2025-11-18T14:20:07.166993Z",
     "shell.execute_reply.started": "2025-11-18T14:20:07.043229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN:\n",
      "  angry: 4736\n",
      "  disgust: 4736\n",
      "  fear: 4736\n",
      "  happy: 9118\n",
      "  neutral: 6533\n",
      "  sad: 5228\n",
      "  surprise: 4736\n",
      "  TOTAL: 39823\n",
      "\n",
      "VAL:\n",
      "  angry: 592\n",
      "  disgust: 592\n",
      "  fear: 592\n",
      "  happy: 1140\n",
      "  neutral: 816\n",
      "  sad: 654\n",
      "  surprise: 592\n",
      "  TOTAL: 4978\n",
      "\n",
      "TEST:\n",
      "  angry: 592\n",
      "  disgust: 592\n",
      "  fear: 592\n",
      "  happy: 1140\n",
      "  neutral: 817\n",
      "  sad: 653\n",
      "  surprise: 592\n",
      "  TOTAL: 4978\n"
     ]
    }
   ],
   "source": [
    "# Count files in each split\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    total = 0\n",
    "    for emotion in EMOTIONS:\n",
    "        path = PROCESSED_DIR / split / emotion\n",
    "        count = len(list(path.glob('*.*')))\n",
    "        total += count\n",
    "        print(f\"  {emotion}: {count}\")\n",
    "    print(f\"  TOTAL: {total}\")\n",
    "\n",
    "# TODO: Add assertions to verify counts match expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Split Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save split DataFrames for reference\n",
    "train_df.to_csv('../results/metrics/train_split.csv', index=False)\n",
    "val_df.to_csv('../results/metrics/val_split.csv', index=False)\n",
    "test_df.to_csv('../results/metrics/test_split.csv', index=False)\n",
    "\n",
    "# Save split info\n",
    "split_info = {\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'train_ratio': TRAIN_RATIO,\n",
    "    'val_ratio': VAL_RATIO,\n",
    "    'test_ratio': TEST_RATIO,\n",
    "    'train_count': len(train_df),\n",
    "    'val_count': len(val_df),\n",
    "    'test_count': len(test_df),\n",
    "    'operation': OPERATION\n",
    "}\n",
    "\n",
    "with open('../results/metrics/split_info.yaml', 'w') as f:\n",
    "    yaml.dump(split_info, f)\n",
    "\n",
    "print(\"‚úÖ Split information saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Data Loading (PyTorch)\n",
    "\n",
    "**Quick test**: Verify we can load images with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T14:20:40.819799Z",
     "iopub.status.busy": "2025-11-18T14:20:40.819234Z",
     "iopub.status.idle": "2025-11-18T14:20:44.858638Z",
     "shell.execute_reply": "2025-11-18T14:20:44.857665Z",
     "shell.execute_reply.started": "2025-11-18T14:20:40.819763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loading test passed\n",
      "Batch shape: torch.Size([32, 3, 224, 224])\n",
      "Labels shape: torch.Size([32])\n",
      "Class mapping: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement basic PyTorch data loading test\n",
    "# Hints:\n",
    "# 1. Import torchvision.transforms\n",
    "# 2. Create ImageFolder dataset\n",
    "# 3. Create DataLoader\n",
    "# 4. Load one batch\n",
    "# 5. Print shapes\n",
    "\n",
    "try:\n",
    "    from torchvision import datasets, transforms\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    # Basic transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # Load train set\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        root=str(PROCESSED_DIR / 'train'),\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Test loading\n",
    "    images, labels = next(iter(train_loader))\n",
    "    print(f\"‚úÖ Data loading test passed\")\n",
    "    print(f\"Batch shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Class mapping: {train_dataset.class_to_idx}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Data loading test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "‚úÖ **Completed**:\n",
    "- Loaded image paths\n",
    "- Created stratified splits\n",
    "- Verified distributions\n",
    "- Copied/moved files\n",
    "- Tested data loading\n",
    "\n",
    "üìÇ **Output Structure**:\n",
    "```\n",
    "data/processed/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ angry/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ happy/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ val/\n",
    "‚îî‚îÄ‚îÄ test/\n",
    "```\n",
    "\n",
    "üéØ **Next Steps**:\n",
    "1. Run baseline model training\n",
    "2. Evaluate on validation set\n",
    "3. Iterate and improve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
